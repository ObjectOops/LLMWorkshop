


Deming Chen 





Professor
Abel Bliss Professor of Engineering


(217) 244-3922
dchen@illinois.edu
250 Coordinated Science Lab


For More Information
Professor Chen's Home Page

Education
Ph.D. in Computer Science,
University of California at Los Angeles,
2005
B.S. Computer Science,	
University of Pittsburgh, 
Pittsburgh, Pennsylvania,
1995

BiographyDr. Deming Chen obtained his BS in computer science from University of Pittsburgh, Pennsylvania in 1995, and his MS and PhD in computer science from University of California at Los Angeles in 2001 and 2005 respectively. He worked as a software engineer between 1995-1999 and 2001-2002. He joined the ECE department of University of Illinois at Urbana-Champaign in 2005 and has been a full professor in the same department since 2015. He is a research professor in the Coordinated Science Laboratory and an affiliate professor in the CS department. His current research interests include reconfigurable computing, cloud computing, system-level and high-level synthesis, machine learning and IoT, and hardware security. He has given more than 160 invited talks sharing these research results worldwide. His work has had a significant impact, with open-source solutions adopted by industry, such as FCUDA, DNNBuilder, CSRNet, SkyNet, ScaleHLS, and Medusa. Notably, Medusa has been integrated into Nvidia's TensorRT-LLM, improving the speed of large language model (LLM) execution by 1.9-3.6x. Dr. Chen has been a technical committee member for a series of top conferences and symposia on EDA, FPGA, low-power design, and embedded systems design. He has also served as General or TPC Chair, Track Chair, Session Chair, Panelist, Panel Organizer, or Moderator for many of these conferences. He has been an associated editor for IEEE TCAD, ACM TODAES, IEEE TVLSI, ACM TRETS, IEEE TCAS-I and TCAS-II, IEEE Design & Test, IET Cyber-Physical Systems, JCSC, and JOLPE. He obtained the Achievement Award for Excellent Teamwork from Aplus Design Technologies in 2001, the Arnold O. Beckman Research Award from UIUC in 2007, the NSF CAREER Award in 2008, ten Best Paper Awards, a TCFPGA Hall-of-Fame paper award, and a few Best Poster Awards. He also received the ACM SIGDA Outstanding New Faculty Award in 2010, IBM Faculty Award in 2014 and 2015, and Google Faculty Award in 2020. In 2017 and 2019 respectively, he led a team to win the First Place Winner Award of DAC International System Design Contest. He is the Donald Willett Faculty Scholar and the Abel Bliss Professor of the Grainger College of Engineering, an IEEE Fellow, an ACM Distinguished Speaker, and the Editor-in-Chief of ACM Transactions on Reconfigurable Technology and Systems (TRETS). Under his leadership, the impact factor of ACM TRETS has increased by 3.8 times. He is the Director of the AMD-Xilinx Center of Excellence and the Co-Director of the IBM-Illinois Discovery Accelerator Institute. He has given a series of Keynote or Plenary speeches at various conferences. He is also included in the List of Teachers Ranked as Excellent in 2008 and 2017 from UIUC. Dr. Chen was involved in several startup companies. He implemented his published algorithm on CPLD technology mapping when he was a software engineer in Aplus Design Technologies, Inc. in 2001, and the software was exclusively licensed by Altera (now part of Intel) and distributed to many customers of Altera worldwide. He is one of the inventors of the xPilot High Level Synthesis package developed at UCLA, which was licensed to AutoESL Design Technologies, Inc. Aplus was acquired by Magma in 2003, and AutoESL was acquired by Xilinx in 2011. In 2016, he co-founded a new startup, Inspirit IoT, Inc.
Professional Highlights
New! SnapKV: SnapKV is an innovative and fine-tuning-free approach that efficiently minimizes KV cache size while still delivering comparable performance in real-world applications.
We discover that each attention head in the model consistently focuses on specific prompt attention features during generation. Meanwhile, this robust pattern can be obtained from an 'observation' window located at the end of the prompts. Drawing on this insight, SnapKV automatically compresses KV caches by selecting clustered important KV positions for each attention head. Our approach significantly reduces the growing computational overhead and memory footprint when processing long input sequences. Specifically, SnapKV achieves a consistent decoding speed with a 3.6x increase in generation speed and an 8.2x enhancement in memory efficiency compared to the baseline when processing inputs of 16K tokens. At the same time, it maintains comparable performance to the baseline models across 16 long sequence datasets. Moreover, SnapKV can process up to 380K context tokens on a single A100-80GB GPU using HuggingFace implementation with minor changes, exhibiting only a negligible accuracy drop in the Needle-in-a-Haystack test. Further comprehensive studies suggest SnapKV's potential for practical applications.
Available since 2024. 
Download: https://github.com/FasterDecoding/SnapKV (210 stars so far)

New! Medusa: Medusa is an efficient method that augments LLM inference by adding extra decoding heads to predict multiple subsequent tokens in parallel. Using a tree-based attention mechanism, Medusa constructs multiple candidate continuations and verifies them simultaneously in each decoding step. By leveraging parallel processing, Medusa substantially reduces the number of decoding steps required. Moreover, we propose several extensions that improve or expand the utility of Medusa, including a self-distillation to handle situations where no training data is available and a typical acceptance scheme to boost the acceptance rate while maintaining generation quality. We evaluate Medusa on models of various sizes and training procedures, and our experiments demonstrate that Medusa can improve the LLM execution speed on GPUs by 2.2-3.6x.
Available since 2024. 
Download: https://github.com/FasterDecoding/Medusa (2.4k stars so far)

New! ISDC: ISDC is a novel feedback-guided iterative system of difference constraints (SDC) scheduling algorithm for high-level synthesis (HLS). ISDC leverages subgraph extraction-based low-level feedback from downstream tools like logic synthesizers to iteratively refine HLS scheduling. Technical innovations include: (1) An enhanced SDC formulation that effectively integrates low-level feedback into the linear-programming (LP) problem; (2) A fanout and window-based subgraph extraction mechanism driving the feedback cycle; (3) A no-human-in-loop ISDC flow compatible with a wide range of downstream tools and process design kits (PDKs). Evaluation shows that ISDC reduces register usage by 28.5% against an industrial-strength open-source HLS tool. Available since 2024. Download:  https://github.com/google/xls
NEW! PandoGen: An ability to forecast future viral individuals at the sequence level enables advance preparation by characterizing the sequences and closing vulnerabilities in current preventative and therapeutic methods. In this work, we explore, in the context of a viral pandemic, the problem of generating complete instances of undiscovered viral protein sequences, which have a high likelihood of being discovered in the future using protein language models. Our novel method, called PandoGen, trains protein language models towards the pandemic protein forecasting task. PandoGen combines techniques such as synthetic data generation, conditional sequence generation, and reward-based learning, enabling the model to forecast future sequences, with a high propensity to spread. Applying our method to modeling the SARS-CoV-2 Spike protein sequence, we find empirically that our model forecasts twice as many novel sequences with five times the case counts compared to a model that is 30× larger. Our method forecasts unseen lineages months in advance. Available since 2024. Download:  https://github.com/UIUC-ChenLab/PandoGen
New! NimBlock: This project focuses on enabling virtualization features to facilitate fine-grained FPGA sharing. We employ an overlay architecture which enables arbitrary, independent user logic to share portions of a single FPGA by dividing the FPGA into independently reconfigurable slots. We then explore scheduling possibilities to effectively time- and space-multiplex the virtualized FPGA. The Nimblock scheduling algorithm balances application priorities and performance degradation to improve response time and reduce deadline violations. We achieve up to 5.7× lower average response times when compared to a no-sharing and no-virtualization scheduling algorithm and up to 2.1× average response time improvement over competitive scheduling algorithms that support sharing within our virtualization environment. Available since 2023. Download:  https://github.com/UIUC-ChenLab/Nimblock
NEW! ScaleHLS+HIDA: ScaleHLS is a High-level Synthesis (HLS) framework on MLIR. ScaleHLS can compile HLS C/C++ or PyTorch model to optimized HLS C/C++ in order to generate high-efficiency RTL design using downstream tools, such as AMD Vitis HLS. By using the MLIR framework that can be better tuned to particular algorithms at different representation levels, ScaleHLS is more scalable and customizable towards various applications coming with intrinsic structural or functional hierarchies. Working with a set of neural networks modeled in PyTorch, ScaleHLS-generated hardware designs provide up to 3825x higher performances compared to the baseline designs that do not contain pragma directives and are only optimized by Xilinx Vivado HLS. Furthermore, HIDA (ScaleHLS 2.0) achieves an 8.54x higher throughput on average compared to that of ScaleHLS. Meanwhile, despite being fully automated and able to handle various applications, HIDA achieves a 1.29x higher throughput over DNNBuilder, a state-of-the-art RTL-based neural network accelerator on FPGAs. Available since 2022. (>3000 downloads.) Download: https://github.com/UIUC-ChenLab/ScaleHLS-HIDA
NEW! PyLog: PyLog is a high-level, algorithm-centric Python-based programming and synthesis flow for FPGA. PyLog is powered by a set of compiler optimization passes and a type inference system to generate high-quality design. PyLog takes in Python functions, generates PyLog intermediate representation (PyLog IR), performs several optimization passes, including pragma insertion, design space exploration, and memory customization, etc., and creates the complete FPGA system design. PyLog also has a runtime that allows users to run the PyLog code directly on the target FPGA platform without any extra code development. Available since 2021. Download: https://github.com/hst10/pylog
NEW! HELLO: HELLO is a new DNA variant calling tool, where we use novel DNN (Deep Neural Network) architectures and customized variant inference functions that account for the underlying nature of sequencing data. Our method allows vastly smaller DNNs to outperform the Inception-v3 architecture used in DeepVariant for indel and substitution-type variant calls. Our improved accuracy and problem-specific customization of DNN models could enable more accurate pipelines and further method development in the field. Available since 2021. Download: https://github.com/anands-repo/hello 
SkyNet: SkyNet is a new hardware-efficient DNN model specialized in object detection and tracking. SkyNet was developed based on the SkyNet Design Methodology to facilitate edge AI solutions, and demonstrated in the 56th IEEE/ACM Design Automation Conference System Design Contest (DAC-SDC), a low power object detection challenge for real-life unmanned aerial vehicle (UAV) applications. SkyNet won the First Place Award for both GPU and FPGA tracks of the contest in 2019. Available since 2019.
Download: https://github.com/TomG008/SkyNet
DNNBuilder (Open Source): This package provides a novel solution that can automatically convert the Caffe trained DNN to the FPGA RTL level implementation without involving any hardware programming effort. It also provides uniform APIs to the users for their AI recognition task. The developers, without any FPGA programming experience, can deploy their FPGA accelerated deep learning services for both cloud and edge computing, only by providing their trained Caffe models. The paper for DNNBuilder has won the IEEE/ACM William J. McCalla ICCAD Best Paper Award in 2018. Download: https://github.com/IBM/AccDNN

Cloud-DNN (Open Source): A framework that maps DNN (deep neural network) models trained by Caffe to FPGAs in the cloud for inference acceleration. It takes the input *.prototxt DNN description, generates corresponding C++ network description, and then produces the final hardware accelerator IPs through high-level synthesis. The goal of Cloud-DNN is to provide more flexible and user-friendly DNN acceleration on cloud-FPGAs (e.g., AWS F1). Download: https://github.com/microideax/Open-Dnn
RIP (Open Source): This open source project contains three inter-related software packages (fast software modeling, fast hardware modeling and design space exploration, and hardware/software co-design), for the ultimate task of automated hardware/software partitioning targeting either sophisticated SoC designs or computing on heterogeneous systems. The paper for fast hardware modeling and DSE embedded in this package has won the IEEE/ACM William J. McCalla ICCAD Best Paper Award in 2015. Download: https://github.com/UIUC-ChenLab/rip
FCUDA (Open Source): A system-synthesis compiler to map GPU CUDA code to FPGA. Enable a common frontend language for heterogeneous compute platforms where FPGA and GPU co-exist. Low-power FPGA computing with comparable performance as GPU. FCUDA project has produced two Best Paper Awards for the conferences SASP'09 and FCCM'11. Download: http://dchen.ece.illinois.edu/tools.html

Research StatementThe spectacular CMOS technology scaling has created a large design productivity gap due to inherent design complexities and deep submicron issues. Development cost, including both the design cost and manufacturing cost, of integrated circuits has grown significantly given the increasing size of the design team and the lengthy design cycles. Meanwhile, intensive computational demands arising from emerging workloads, such as those in various IoT and deep-learning related domains, require new architecture and hardware designs, novel automated design flows, and efficient accelerator deployments both at the edge and in the cloud. In this context, the research group led by Prof. Chen mainly pursues the following research directions: system-level and high-level design automation, machine learning and cognitive computing, hybrid cloud, hardware/software co-design, and FPGA and GPU computing. The group recently is also pursuing several other research directions, such as computational genomics and hardware system security.
Graduate Research OpportunitiesWe are recruiting. If you are passionate about research, inspired for innovation and impact, determined to pursue a Ph.D. in Computer Engineering, and your research interests match one or more topics as listed in the "RESEARCH INTERESTS" section below, please contact Prof. Chen directly through email and attach your detailed CV.
Undergraduate Research OpportunitiesWe are looking for committed and mature undergrad researchers for the following topics: FPGA and GPU computing, machine learning and hardware acceleration, high-level and system-level synthesis, and security in IoT and smart grid.
Research Interests
Hardware security
GPU optimization and GPU computing
IoT and data analytics 
Hardware/software co-design for SoC
System-level and high-level synthesis
Cloud computing
AI, machine learning and hardware acceleration
Reconfigurable computing and FPGAs


Research Areas
Algorithms and computational complexity
Architecture, Compilers, and Parallel Computing
Computer aided design
Computer aided design of integrated circuits
Digital integrated circuits
Fault tolerance and reliability
Hardware verification and testing
Integrated circuit reliability
Logic design and VLSI
Nano-electronics and single electronics


Research Topics
Autonomous Systems and Artificial Intelligence
Autonomous vehicular technology, UAVs
Bioelectronics and Bioinformatics
Cognitive computing
Computational science and engineering
Cyberinfrastructures
Cyberphysical systems and internet of things
Cybersecurity and privacy
Data science and analytics
Data/Information Science and Systems
Distributed computing and storage systems
Energy
Genomics
Machine learning
Machine vision
Nanomedicine and bio-nanotechnology
Point-of-care diagnostics
Robotics
Smart grid and energy delivery
Smart infrastructures
Speech, language, and audio processing
Wearable and mobile computing

Patents
U.S. Patent Application No.: 18/328,716. Filing date: June 2023.
Co-inventors: Bharat Sukhwani, Martin Ohmacht, Hubertus Franke, Sameh Asaad, Scott Smith, Deming Chen.
Title: “Dynamic Assignment of Device Queues to Virtual Functions to Provide to Virtual Machines”.
U.S. Patent No.: 11,706,163. Issue date: July 2023.
Co-inventors: Jian Huang, Deming Chen, Alexander Gerhard Schwing, Youjie Li.
Title: “Accelerating Distributed Reinforcement Learning with In-switch Computing”. 
Technology license: a company licensed the "Low Loss DNN Quantization Software" out of ADSC/UIUC in 2021.
Co-inventors: Yao Chen, Deming Chen, Cong Hao.
Technology license: a company licensed the RASP technology out of UCLA, 2017. Co-inventors: Deming Chen, Jason Cong, Eugene Ding, Zhijun Huang, Yeanyow Hwang, Chang Wu, Sarah Xu. Title: RASP: FPGA/CPLD Technology Mapping and Synthesis Package. 
Technology license: Inspirit IoT, Inc. licensed the VAST HLS technology out of ADSC/UIUC, 2016. Co-inventors: Deming Chen, Hongbin Zheng, Kyle Rupnow, Swathi Gurumani. Title: VAST: High-level Synthesis Tool.
Technology license: AutoESL Inc. licensed the xPilot technology out of UCLA, 2006. Co-inventors: Deming Chen, Jason Cong, Yiping Fan, Guoling Han, Wei Jiang, and Zhiru Zhang. Title: xPilot: A Platform-Based Behavioral Synthesis System. This technology eventually led to the acquisition of AutoESL by Xilinx. xPilot became the high-level synthesis engine of Xilinx Vivado HLS (high-level synthesis).
Patent No. 3304111. Issue date:  Mar 11, 2020.
Title: System-Level Validation of Systems-On-A-Chip (SOC).
Co-inventors: Keith A. Campbell, Hai Lin, Deming Chen, and Subhasish Mitra.

Journal Editorships
Editor-in-Chief, ACM Transactions on Reconfigurable Technology and Systems (TRETS), 2019-2025
Guest Editor and main contact, Special Issue of IEEE Design & Test Magazine on Machine Intelligence at the Edge, 2018-2019
Lead Guest Editor, Special Issue of Integration, the VLSI Journal on Hardware Acceleration for Machine Learning, 2018-2019

Conferences Organized or Chaired
Founding General co-chair, the First IEEE International Workshop on LLM-Aided Design (LAD'24), June 2024 
TPC Track chair, IEEE/ACM Design Automation Conference (DAC), 2024
Technical Program Vice chair, IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2024

Professional Societies
Vice President for Awards, IEEE Council on EDA, 2024-present
Member and Cohort FEC Representative, CEDA IEEE Fellow Evaluation Committee (FEC), 2024, 2025
Member, ACM SIGDA Outstanding New Faculty Award Committee, 2024
Chair, IEEE CEDA Fellow Evaluation Committee, 2023
Member, ACM SIGDA Outstanding New Faculty Award Committee, 2022
Chair, IEEE CEDA Fellow Evaluation Committee, 2022
Founding Chair, IEEE CEDA Central Illinois Chapter, 2016-2023 

Service on Department Committees
ECE Named Appointments Committee, 2022-2024
Chair, ECE Graduate Committee, 2020-2022
CE Area Chair, 2015-2017
CSL Policy and Planning Committee, 2008-2010, 2011-2012, 2014-2015, 2021

Service on College Committees
Hybrid Cloud Thrust Co-lead, IBM-Illinois Discovery Accelerator Institute, 2021 - 2024
Chief Scientist, IBM-Illinois Center for Cognitive Computing Systems Research, 2020 - 2021
Steering Committee member, C-NICE center, Grainger College of Engineering, 2019 - present
Director, AMD/Xilinx Center of Excellence, 2020 - present
Representative of CSL on the College Executive Committee, 2016-2019

Service on Campus Committees
Senator, Faculty Senate, 2014-2016, 2018-2020, 2022-2024

Honors
Keynote Speaker, Workshop on Reconfigurable Computing (WRC), 2025
Co-Director, IBM-Illinois Discovery Accelerator Institute, 10/24-present
Keynote Speaker, 31st Reconfigurable Architectures Workshop (RAW), 2024
Vice President for Awards, IEEE Council on EDA, 2024-present
Best Poster Award, ASPDAC, 2024
Best Poster and First Place Winner Award, DAC Ph.D. Forum, 2023
Chair, IEEE CEDA Fellow Evaluation Committee, 2022 & 2023
Distinguished Speaker, Distinguished Speaker Series, ECE, Northwestern University, 2022
Induction of the "FCUDA: Enabling efficient compilation of CUDA kernels onto FPGAs" paper into the TCFPGA Hall of Fame for FPGAs, 2022
Second Place Winner, System Design Contest at IEEE/ACM Design Automation Conference, 2021
Best Paper Award, International Conference on Intelligent Data Engineering and Automated Learning, 2021
ACM SIGDA Distinguished Service Award, 2021
Keynote Speaker, International Conference on Intelligent Data Engineering and Automated Learning (IDEAL), 2021
Distinguished Speaker, Distinguished Speaker Series, Universidad Catolica San Pablo, 2021
Google Faculty Award, for supporting machine learning courses, diversity and inclusion, 2020.
Keynote Speaker, IEEE International Conference on Field-Programmable Technology, 2020
Distinguished Speaker, Distinguished Speaker Series, ECE, Rice University, 2020
Keynote Speaker, ACM Great Lakes Symposium on VLSI, 2020
Distinguished Speaker, Distinguished Speaker Series, ACM Sacramento Chapter, 2020
Keynote Speaker, ROAD4NN: Research Open Automatic Design for Neural Networks, 2020
Best Paper Award, IEEE International Conference on VLSI Design, 2020
Abel Bliss Professor of Engineering, 2020 - present
Keynote Speaker, Computing Conference, 2019
Editor-in-Chief, ACM Transactions on Reconfigurable Technology and Systems, 2019-2025
IEEE Fellow, 2019
ACM Distinguished Speaker, 2019-2022
First Place Winner, both the FPGA and the GPU categories, System Design Contest at IEEE/ACM Design Automation Conference, 2019
Best Poster Award, Joint Workshop on On-Device Machine Learning & Compact Deep Neural Network Representations (ODML-CDNNR), 2019
Invited Distinguished Speaker, COOL Chips, 2019
Best Paper Award, IEEE/ACM Intl Conf on Computer-Aided Design, 2018
Keynote Speaker, International Conference on Big Data Analytics & Data Mining, 2018
Best Paper Award, IEEE/ACM Intl Workshop on System-Level Interconnect Prediction, 2018
Plenary Speech, IEEE Computer Society Annual Symposium on VLSI, 2018
First Place Winner, Intl Hardware Design Contest, Design Automation Conf, 2017
Keynote paper, Integration, the VLSI Journal, 2017
Best Paper Award, IEEE/ACM Intl Conf on Computer-Aided Design, 2015
Keynote speech, IEEE International Conference on ASIC, 2015
Keynote speech, IEEE International Conference on Anti-counterfeiting, Security, and Identification, 2014
IBM Faculty Award, 2014 and 2015
Best Paper Award, IEEE Intl Conf on Hardware/Software Codesign and System
Synthesis, 2013
Best Paper Award, Symp on Application Accelerators in High Performance Computing, 2011 
Best Paper Award, IEEE Intl Symp on Field-Programmable Custom Computing Machines, 2011
ACM SIGDA Outstanding New Faculty Award, 2010
Best Paper Award, IEEE Symp on Application Specific Processors, 2009
Best Paper Award, IEEE/ACM Asia and South Pacific Design Automation Conf, 2009
CAREER Award, National Science Foundation, 2008
Arnold O. Beckman Research Award, UIUC, 2007
Achievement Award for Excellent Teamwork, Aplus Design Technologies, Inc, 2001

Teaching Honors
On the List of Teachers Ranked as Excellent by Students, Spring 2008, Fall 2017

Public Service Honors
Founding Chair of IEEE CEDA chapter for Central Illinois (12/1/2016)

Recent Courses TaughtECE 411 - Computer Organization & Design
ECE 479 (ECE 498 ICC, ECE 498 IL1, ECE 498 IL2, ECE 498 IL3, ECE 498 IL4) - IoT and Cognitive Computing
ECE 527 - System-On-Chip Design

